# -*- coding: utf-8 -*-
"""Data_Prepare_Houston13_SSL_HSI_final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uy2Lwg0w7pAWG-m-87pUZ9-cuNm1EBpu
"""

import tensorflow as tf
import scipy.io as sio
import numpy as np
import tqdm

# Gen indices of the labels
def get_gt_index(y):

  shapeY = np.shape(y)

  pp,qq = np.unique(y, return_counts=True)
  sum1 = np.sum(qq)-qq[0]

  index = np.empty([sum1,3], dtype = 'int')

  cou = 0
  for k in tqdm.tqdm(range(1,np.size(np.unique(y)))):
    for i in range(shapeY[0]):
      for j in range(shapeY[1]):
        if y[i,j] == k:
          index[cou,:] = np.expand_dims(np.array([k,i,j]),0)
          cou = cou+1
  return index

# The code takes the entire hsi/lidar image as input for 'X' and grounttruth file as input for 'y'
# and the patchsize as for 'windowSize'.
# The output are the patches centered around the groundtruth pixel, the corresponding groundtruth label and the
# pixel location of the patch.

def make_patches(X, y, windowSize):

  shapeX = np.shape(X)

  margin = int((windowSize-1)/2)
  newX = np.zeros([shapeX[0]+2*margin,shapeX[1]+2*margin,shapeX[2]], dtype = 'uint8')

  newX[margin:shapeX[0]+margin:,margin:shapeX[1]+margin,:] = X

  index = get_gt_index(y)

  patchesX = np.empty([index.shape[0],2*margin+1,2*margin+1,shapeX[2]], dtype = 'uint8')
  patchesY = np.empty([index.shape[0]],dtype = 'uint8')

  for i in range(index.shape[0]):
    p = index[i,1]
    q = index[i,2]
    patchesX[i,:,:,:] = newX[p:p+windowSize,q:q+windowSize,:]
    patchesY[i] = index[i,0]

  return patchesX, patchesY, index

# Read Houston 2013 data
data = sio.loadmat('/content/gdrive/MyDrive/datasets/H13/houston_data.mat')

import sys
import numpy

# normalize the features
feats = data['hsi']
feats_norm = np.empty([349,1905,144], dtype = 'float32')
for i in tqdm.tqdm(range(144)):
  feats_norm[:,:,i] = feats[:,:,i]-np.min(feats[:,:,i])
  feats_norm[:,:,i] = feats_norm[:,:,i]/np.max(feats_norm[:,:,i])

# Transform to uint8 data
feats_norm = 255*feats_norm
feats_norm = feats_norm.astype('uint8')

import matplotlib.pyplot as plt
plt.imshow(np.concatenate([np.expand_dims(feats_norm[:,:,105], axis = 2),
                           np.expand_dims(feats_norm[:,:,95], axis = 2),
                           np.expand_dims(feats_norm[:,:,85], axis = 2)], axis = 2))

# Save normalised bands  features
np.save('feats_norm', feats_norm)

"""# **Annotated Samples**"""

# Function to get the indices of train and test samples.
# 100 samples per class are chosen for training

index = get_gt_index(data['train'])
def train_test_samples(data):

    r,c = np.shape(data)
    data_sort = data
    train_sample = 100

    clas, count = np.unique(data_sort[:,0], return_counts=True)
    index1 = np.zeros((1,1), dtype = 'int')
    k = np.expand_dims(count, axis = 1)
    index2 = np.concatenate((index1, k), axis = 0)
    index2_cumsum = np.cumsum(index2)
    train = np.zeros((0,c), dtype = 'float')

    for j in range(np.size(clas)):

      if index2[j+1]<100:
        train_sample = int(index2[j+1])
      else:
        train_sample = 100

      temp = data_sort[index2_cumsum[j]:index2_cumsum[j+1]]
      np.random.shuffle(temp)
      s1, _ = np.shape(temp)
      train_temp = temp[0:train_sample,:]
      train = np.concatenate((train, train_temp), axis = 0)

    return train

# Get the indices of train and test samples

train_index = train_test_samples(index)

# Get train samples (100 samples per class)

gt_train = np.zeros([349,1905], dtype = 'int')
for i in range(1500):
  gt_train[train_index[i,1].astype('int'), train_index[i,2].astype('int')] = train_index[i,0]

test = data['test']
train_patches, train_labels, index_train = make_patches(feats_norm, gt_train, 9) #patch_size = 9
test_patches, test_labels, index_test = make_patches(feats_norm, test, 9) #patch_size = 9

np.save('train_patches', train_patches)
np.save('train_labels', train_labels)
np.save('test_patches', test_patches)
np.save('test_labels', test_labels)

"""# **Unannotated Samples**"""

## Ensuring around 70% overlapping patches
feats_sub = feats_norm[5:349-5, 5:1905-5, :]
feats1 = feats_sub[0:339-1, 0:1895-2,:]
feats2 = feats_sub[1:339, 2:1895,:]

patches1 = np.empty((154324,9,9,144), dtype = 'uint8')
patches2 = np.empty((154324,9,9,144), dtype = 'uint8')
k = 0
for i in tqdm.tqdm(range(0,338-9,2)):
  for j in range(0,1893-9,4):
    patches1[k,:,:,:] = feats1[i:i+9,j:j+9,:]
    patches2[k,:,:,:] = feats2[i:i+9,j:j+9,:]
    k = k+1

np.save('patches1_no_label', patches1)
np.save('patches2_no_label', patches2)